{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Fine-tuning with Vulkan GPU\n",
    "\n",
    "**Adapted from:** Original blog post\n",
    "**Platform:** macOS + krunkit\n",
    "**Note:** Uses CPU backend with Vulkan compute benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"GPU Device:\", 'Available' if os.path.exists('/dev/dri/renderD128') else 'Not found')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# macOS: Use CPU (Vulkan benefits underlying operations)\n",
    "device = torch.device('cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (smaller for macOS)\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "print(f\"✅ Model loaded\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample dataset\n",
    "texts = [f\"Sample text {i}\" for i in range(100)]\n",
    "labels = [i % 2 for i in range(100)]\n",
    "\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_ids': encodings['input_ids'],\n",
    "    'attention_mask': encodings['attention_mask'],\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} samples\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training (adapted for macOS)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/tmp/distilbert-test\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    # Note: No use_cuda on macOS\n",
    "    # Vulkan GPU helps with compute operations\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "import time\n",
    "start = time.time()\n",
    "trainer.train()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"✅ Training complete!\")\n",
    "print(f\"Time: {elapsed:.2f}s\")\n",
    "print(f\"Platform: macOS + Vulkan GPU\")\n",
    "print(\"Benefit: Vulkan accelerates compute vs pure CPU\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
